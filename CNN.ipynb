{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1fxaih9KYbL-hmib5GMumcEMn1EngLXP9",
      "authorship_tag": "ABX9TyPJ4QziT1YCj9pd7uAYgxls",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JiatingLi/CNN_SoybeanIDC/blob/main/CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRJAbHftghAY"
      },
      "source": [
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "\r\n",
        "from keras.models import Model\r\n",
        "from keras.optimizers import Adam\r\n",
        "from keras.layers import Input,Dense,Flatten,Activation,Conv2D,MaxPooling2D\r\n",
        "from keras.layers.normalization import BatchNormalization\r\n",
        "from keras.initializers import TruncatedNormal\r\n",
        "from keras_preprocessing.image import ImageDataGenerator\r\n",
        "\r\n",
        "from matplotlib import pyplot as plt\r\n",
        "from pandas import DataFrame\r\n",
        "from skimage.transform import resize\r\n",
        "from sklearn.metrics import mean_squared_error\r\n",
        "from math import sqrt\r\n",
        "from statistics import mean"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mF5RwGSqgiy_"
      },
      "source": [
        "#### DATA PREPARATION\r\n",
        "training_dir = '/content/drive/MyDrive/SoybeanIDC_CNN_Regression/Valley711_RIL/'\r\n",
        "testing_dir = '/content/drive/MyDrive/SoybeanIDC_CNN_Regression/Valley711_NAM/'\r\n",
        "\r\n",
        "training_label ='/content/drive/MyDrive/SoybeanIDC_CNN_Regression/Valley711_RIL.csv'\r\n",
        "testing_label = '/content/drive/MyDrive/SoybeanIDC_CNN_Regression/Valley711_NAM.csv'\r\n",
        "training_label = pd.read_csv(training_label, delimiter=',', header=0, names=['filename', 'IDC'])\r\n",
        "testing_label = pd.read_csv(testing_label, delimiter=',', header=0, names=['filename', 'IDC'])\r\n",
        "\r\n",
        "testing_y = np.array(testing_label['IDC']) #true IDC scores for testing dataset\r\n",
        "\r\n",
        "img_width, img_height = 224, 448 \r\n",
        "\r\n",
        "## Read data using flow_from_dataframe()\r\n",
        "datagen=ImageDataGenerator(rescale=1./255.,validation_split=0.2)\r\n",
        "test_datagen=ImageDataGenerator(rescale=1./255.)\r\n",
        "\r\n",
        "train_generator=datagen.flow_from_dataframe(\r\n",
        "    dataframe=training_label,\r\n",
        "    directory=training_dir,\r\n",
        "    x_col='filename', \r\n",
        "    y_col='IDC',\r\n",
        "    subset=\"training\",\r\n",
        "    batch_size=32,\r\n",
        "    seed=22,\r\n",
        "    shuffle=True,\r\n",
        "    class_mode='raw',\r\n",
        "    target_size=(img_height,img_width))\r\n",
        "\r\n",
        "valid_generator=datagen.flow_from_dataframe(\r\n",
        "    dataframe=training_label,\r\n",
        "    directory=training_dir,\r\n",
        "    x_col='filename', \r\n",
        "    y_col='IDC',\r\n",
        "    subset=\"validation\",\r\n",
        "    batch_size=32,\r\n",
        "    seed=22,\r\n",
        "    shuffle=True,\r\n",
        "    class_mode=\"raw\",\r\n",
        "    target_size=(img_height,img_width))\r\n",
        "\r\n",
        "test_generator=test_datagen.flow_from_dataframe(\r\n",
        "    dataframe=testing_label,\r\n",
        "    directory=testing_dir,\r\n",
        "    x_col=\"filename\",\r\n",
        "    y_col=None,\r\n",
        "    batch_size=1,\r\n",
        "    seed=22,\r\n",
        "    shuffle=False,\r\n",
        "    class_mode=None,\r\n",
        "    target_size=(img_height,img_width))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0Z5FRsyjXQN"
      },
      "source": [
        "#### Some functions\r\n",
        "def best_fit_slope_and_intercept(xs,ys):\r\n",
        "    m = (((mean(xs)*mean(ys)) - mean(xs*ys)) /((mean(xs)*mean(xs)) - mean(xs*xs)))\r\n",
        "    b = mean(ys) - m*mean(xs)\r\n",
        "    return m, b\r\n",
        "\r\n",
        "def squared_error(y_true,y_line):\r\n",
        "    return sum((y_line - y_true) * (y_line - y_true))\r\n",
        "\r\n",
        "def coefficient_of_determination(y_true,y_line):\r\n",
        "    y_mean_line = [mean(y_true) for y in y_true]\r\n",
        "    squared_error_regr = squared_error(y_true, y_line)\r\n",
        "    squared_error_y_mean = squared_error(y_true, y_mean_line)\r\n",
        "    return 1 - (squared_error_regr/squared_error_y_mean)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dn1SV9CLjnuq"
      },
      "source": [
        "#### Define Model\r\n",
        "inChannel = 3\r\n",
        "input_img = Input(shape = (img_height, img_width, inChannel))\r\n",
        "\r\n",
        "def regres(input_img):\r\n",
        "    x = Conv2D(16, 3, kernel_initializer = TruncatedNormal(mean=0.0, stddev=0.05, seed=22),use_bias=False, padding='same')(input_img) \r\n",
        "    x = BatchNormalization()(x)\r\n",
        "    x = Activation('relu')(x)\r\n",
        "    x = Conv2D(16, 3, kernel_initializer = TruncatedNormal(mean=0.0, stddev=0.05, seed=22),use_bias=False, padding='same')(x)\r\n",
        "    x = BatchNormalization()(x)\r\n",
        "    x = Activation('relu')(x)\r\n",
        "    x = MaxPooling2D(pool_size=(2, 2))(x) \r\n",
        "    \r\n",
        "    x = Conv2D(16, 3, kernel_initializer = TruncatedNormal(mean=0.0, stddev=0.05, seed=22),use_bias=False, padding='same')(x) \r\n",
        "    x = BatchNormalization()(x)\r\n",
        "    x = Activation('relu')(x)\r\n",
        "    x = Conv2D(16, 3, kernel_initializer = TruncatedNormal(mean=0.0, stddev=0.05, seed=22),use_bias=False, padding='same')(x)\r\n",
        "    x = BatchNormalization()(x)\r\n",
        "    x = Activation('relu')(x)\r\n",
        "    x = MaxPooling2D(pool_size=(2, 2))(x) \r\n",
        "     \r\n",
        "    x = Flatten()(x)\r\n",
        "    x = Dense(100,kernel_initializer = TruncatedNormal(mean=0.0, stddev=0.05, seed=22),bias_initializer='zeros')(x)\r\n",
        "    x = Activation('relu')(x)\r\n",
        "    x = Dense(100,kernel_initializer = TruncatedNormal(mean=0.0, stddev=0.05, seed=22),bias_initializer='zeros')(x)\r\n",
        "    x = Activation('relu')(x)\r\n",
        "    x = Dense(1,kernel_initializer = TruncatedNormal(mean=0.0, stddev=0.05, seed=22),bias_initializer='zeros')(x)\r\n",
        "    pred = Activation('linear')(x)\r\n",
        "    return pred \r\n",
        "\r\n",
        "full_model = Model(input_img,regres(input_img))\r\n",
        "full_model.compile(loss='mean_squared_error', metrics=['mean_squared_error'], optimizer=Adam(lr=0.0001))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MD4cotnFjz21"
      },
      "source": [
        "#### TRAIN model\r\n",
        "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\r\n",
        "STEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size\r\n",
        "\r\n",
        "regressor = full_model.fit_generator(generator=train_generator,\r\n",
        "                                     steps_per_epoch=STEP_SIZE_TRAIN,\r\n",
        "                                     validation_data=valid_generator,\r\n",
        "                                     validation_steps=STEP_SIZE_VALID,\r\n",
        "                                     epochs=100)\r\n",
        "\r\n",
        "## plot training process\r\n",
        "loss = regressor.history['loss']\r\n",
        "val_loss = regressor.history['val_loss']\r\n",
        "epochs = range(len(loss))\r\n",
        "plt.figure()\r\n",
        "plt.plot(epochs, loss, 'b', label='Training loss')\r\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss')\r\n",
        "plt.title('Training and validation loss')\r\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aT7hYsgnj6ae"
      },
      "source": [
        "#### PREDICTION\r\n",
        "STEP_SIZE_TEST=test_generator.n//test_generator.batch_size\r\n",
        "test_generator.reset()\r\n",
        "\r\n",
        "predict=full_model.predict_generator(test_generator,steps=STEP_SIZE_TEST,verbose=1)\r\n",
        "\r\n",
        "pred = predict[:,0]\r\n",
        "true = testing_y\r\n",
        "plt.plot(pred,true, 'g^')\r\n",
        "\r\n",
        "# r2 and rmse \r\n",
        "m, b = best_fit_slope_and_intercept(pred,true)\r\n",
        "regression_line = [(m*x)+b for x in pred]\r\n",
        "r2 = coefficient_of_determination(true, regression_line)\r\n",
        "rmse = sqrt(mean_squared_error(true, pred))\r\n",
        "print('r2: %.3f' % r2)\r\n",
        "print('RMSE: %.3f' % rmse)\r\n",
        "\r\n",
        "# ## save\r\n",
        "# df = DataFrame([true,pred])\r\n",
        "# df = df.T #transpose\r\n",
        "# df.to_excel('PATH TO EXPECTED DIRECTORY.xlsx', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}